{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import mmap\n",
    "import datetime\n",
    "import time\n",
    "import threading\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_date(date_str):\n",
    "    \"\"\"Validates if the given date is in the correct format (YYYY-MM-DD).\"\"\"\n",
    "    try:\n",
    "        datetime.datetime.strptime(date_str, \"%Y-%m-%d\")\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chunk(file_path, search_date, start, end, output_file, lock):\n",
    "    \"\"\"Processes a chunk of the log file and extracts relevant logs efficiently.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file, mmap.mmap(file.fileno(), 0, access=mmap.ACCESS_READ) as mm:\n",
    "            chunk = mm[start:end].decode(\"utf-8\", errors=\"ignore\")\n",
    "            logs = [line for line in chunk.split(\"\\n\") if line.startswith(search_date)]\n",
    "\n",
    "        if logs:\n",
    "            with lock:\n",
    "                with open(output_file, \"a\", encoding=\"utf-8\") as out:\n",
    "                    out.writelines(\"\\n\".join(logs) + \"\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error processing chunk: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_size(file_path):\n",
    "    \"\"\"Returns the size of the file in bytes.\"\"\"\n",
    "    try:\n",
    "        return os.path.getsize(file_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå Error: File '{file_path}' not found.\")\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_logs_parallel(log_file, search_date, output_dir=\"output\"):\n",
    "    \"\"\"Extract logs for a specific date from a large log file using threading.\"\"\"\n",
    "    \n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    output_file = os.path.join(output_dir, f\"output_{search_date}.txt\")\n",
    "    \n",
    "    file_size = get_file_size(log_file)\n",
    "    num_workers = os.cpu_count()  # Use all available CPU cores\n",
    "    chunk_size = file_size // num_workers\n",
    "\n",
    "    lock = threading.Lock()\n",
    "    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        futures = []\n",
    "        for i in range(num_workers):\n",
    "            start = i * chunk_size\n",
    "            end = file_size if i == num_workers - 1 else (i + 1) * chunk_size\n",
    "            futures.append(executor.submit(process_chunk, log_file, search_date, start, end, output_file, lock))\n",
    "\n",
    "        for future in futures:\n",
    "            future.result()  # Ensure all threads complete execution\n",
    "\n",
    "    print(f\"‚úÖ Logs for {search_date} saved in {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_small_test():\n",
    "    \"\"\"Runs a test on a small dataset before processing the full file.\"\"\"\n",
    "    test_data = \"\"\"\\\n",
    "2024-12-01 14:23:45 INFO User logged in\n",
    "2024-12-01 14:24:10 ERROR Failed to connect to the database\n",
    "2024-12-02 09:15:30 WARN Disk space running low\n",
    "2024-12-01 16:45:00 INFO File uploaded successfully\n",
    "\"\"\"\n",
    "    test_file = \"test_logs.txt\"\n",
    "    with open(test_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(test_data)\n",
    "\n",
    "    print(\"\\nüü¢ Running test on small dataset...\")\n",
    "    extract_logs_parallel(test_file, \"2024-12-01\")\n",
    "    print(\"üü¢ Test completed. Check 'output/output_2024-12-01.txt'.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    if len(sys.argv) != 2:\n",
    "        print(\"‚ùå Usage: python extract_logs.py YYYY-MM-DD\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    search_date = sys.argv[1]\n",
    "\n",
    "    if not validate_date(search_date):\n",
    "        print(\"‚ùå Error: Invalid date format. Use YYYY-MM-DD.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Run a test on a small dataset before full execution\n",
    "    run_small_test()\n",
    "\n",
    "    log_file = \"logs_2024.log\"  # Replace with actual log file path\n",
    "    print(\"\\nüöÄ Running on the full log file...\\n\")\n",
    "\n",
    "    start_time = time.time()  # Start time tracking\n",
    "    extract_logs_parallel(log_file, search_date)\n",
    "    end_time = time.time()  # End time tracking\n",
    "\n",
    "    print(f\"‚è≥ Execution time: {end_time - start_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
